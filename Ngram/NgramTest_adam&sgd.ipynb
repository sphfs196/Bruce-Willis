{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "def time_since(since):\n",
    "\ts = time.time() - since\n",
    "\tm = math.floor(s/60)\n",
    "\ts -= m*60\n",
    "\treturn '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "CONTEXT_SIZE = 2 \n",
    "EMBEDDING_DIM = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPath = \"4_test.pkl\"\n",
    "argPath = '4_testArg.pt'\n",
    "test_sentence = \"當地警察已在28日下午開始監控人潮，但遊客數量似乎不如預期的多，因為當局目前認定還沒有關閉閘門的必要。威尼斯絡繹不絕的觀光客，已經成為當地人的惡夢。當地巷弄窄小，在旅遊旺季街道幾乎難以行走。\"\n",
    "\n",
    "trigrams = []\n",
    "trigramsList = []\n",
    "trigramsList = [ ([test_sentence[i], test_sentence[i+1]], test_sentence[i+2])\n",
    "            for i in range(len(test_sentence) - 2) ]\n",
    "\n",
    "vocab = set(test_sentence)\n",
    "\n",
    "word_to_ix = {word : i for i, word in enumerate(vocab)}\n",
    "ix_to_word = {i: word for i, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGramLanguageModeler(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        super(NGramLanguageModeler, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embdeds = self.embeddings(inputs).view((1, -1))\n",
    "        out = F.relu(self.linear1(embdeds))\n",
    "        out = self.linear2(out)\n",
    "        log_probs = F.log_softmax(out, dim=1)\n",
    "        return log_probs, self.embeddings\n",
    "\n",
    "model = NGramLanguageModeler(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE)\n",
    "losses = []\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01, eps = 0.1, betas=(0.99, 0.999))\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading pretrained model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ncheckpoint = torch.load(argPath)\\n#args.start_epoch = checkpoint[\\'epoch\\']\\nmodel.load_state_dict(checkpoint[\\'state_dict\\'])\\noptimizer.load_state_dict(checkpoint[\\'optimizer\\'])\\nprint(\"=> loaded checkpoint : (epoch {})\".format(checkpoint[\\'epoch\\']))\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading pretrained model, etc...\n",
    "print('loading pretrained model...')\n",
    "\"\"\"\n",
    "checkpoint = torch.load(argPath)\n",
    "#args.start_epoch = checkpoint['epoch']\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "print(\"=> loaded checkpoint : (epoch {})\".format(checkpoint['epoch']))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"in gpu\")\n",
    "    model.cuda()\n",
    "else:\n",
    "    print(\"in cpu\")\n",
    "    model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:\n",
      "0\n",
      "0m 0s\n",
      "loss:\n",
      "tensor(407.7391)\n",
      "['當', '局', '2', '8', '人', '下', '乎', '人', '光', '。', '的', '乎', '，', '察', '的', '2', '日', '在', '2', '8', '人', '下', '乎', '人', '光', '。', '的', '乎', '，', '察', '的', '2', '日', '在', '2', '8', '人', '下', '乎', '人', '光', '。', '的', '乎', '，', '察', '的', '2', '日', '在', '2', '8']\n",
      "epoch:\n",
      "100\n",
      "0m 5s\n",
      "loss:\n",
      "tensor(5.5251)\n",
      "['當', '局', '目', '前', '認', '定', '還', '沒', '有', '關', '閉', '閘', '門', '的', '必', '要', '。', '威', '尼', '斯', '絡', '繹', '不', '絕', '的', '觀', '光', '客', '，', '已', '經', '成', '為', '當', '地', '人', '的', '惡', '夢', '。', '當', '地', '人', '的', '惡', '夢', '。', '當', '地', '人', '的', '惡']\n",
      "epoch:\n",
      "200\n",
      "0m 11s\n",
      "loss:\n",
      "tensor(5.2207)\n",
      "['當', '局', '目', '前', '認', '定', '還', '沒', '有', '關', '閉', '閘', '門', '的', '必', '要', '。', '威', '尼', '斯', '絡', '繹', '不', '絕', '的', '觀', '光', '客', '，', '已', '經', '成', '為', '當', '地', '人', '的', '惡', '夢', '。', '當', '地', '人', '的', '惡', '夢', '。', '當', '地', '人', '的', '惡']\n",
      "epoch:\n",
      "300\n",
      "0m 16s\n",
      "loss:\n",
      "tensor(5.1022)\n",
      "['當', '局', '目', '前', '認', '定', '還', '沒', '有', '關', '閉', '閘', '門', '的', '必', '要', '。', '威', '尼', '斯', '絡', '繹', '不', '絕', '的', '觀', '光', '客', '，', '已', '經', '成', '為', '當', '地', '人', '的', '惡', '夢', '。', '當', '地', '人', '的', '惡', '夢', '。', '當', '地', '人', '的', '惡']\n",
      "epoch:\n",
      "400\n",
      "0m 21s\n",
      "loss:\n",
      "tensor(5.0403)\n",
      "['當', '局', '目', '前', '認', '定', '還', '沒', '有', '關', '閉', '閘', '門', '的', '必', '要', '。', '威', '尼', '斯', '絡', '繹', '不', '絕', '的', '觀', '光', '客', '，', '已', '經', '成', '為', '當', '地', '人', '的', '惡', '夢', '。', '當', '地', '人', '的', '惡', '夢', '。', '當', '地', '人', '的', '惡']\n",
      "epoch:\n",
      "500\n",
      "0m 27s\n",
      "loss:\n",
      "tensor(5.0133)\n",
      "['當', '局', '目', '前', '認', '定', '還', '沒', '有', '關', '閉', '閘', '門', '的', '必', '要', '。', '威', '尼', '斯', '絡', '繹', '不', '絕', '的', '觀', '光', '客', '，', '已', '經', '成', '為', '當', '地', '人', '的', '惡', '夢', '。', '當', '地', '人', '的', '惡', '夢', '。', '當', '地', '人', '的', '惡']\n",
      "epoch:\n",
      "600\n",
      "0m 33s\n",
      "loss:\n",
      "tensor(4.9728)\n",
      "['當', '局', '目', '前', '認', '定', '還', '沒', '有', '關', '閉', '閘', '門', '的', '必', '要', '。', '威', '尼', '斯', '絡', '繹', '不', '絕', '的', '觀', '光', '客', '，', '已', '經', '成', '為', '當', '地', '人', '的', '惡', '夢', '。', '當', '地', '人', '的', '惡', '夢', '。', '當', '地', '人', '的', '惡']\n",
      "epoch:\n",
      "700\n",
      "0m 38s\n",
      "loss:\n",
      "tensor(4.9515)\n",
      "['當', '局', '目', '前', '認', '定', '還', '沒', '有', '關', '閉', '閘', '門', '的', '必', '要', '。', '威', '尼', '斯', '絡', '繹', '不', '絕', '的', '觀', '光', '客', '，', '已', '經', '成', '為', '當', '地', '人', '的', '惡', '夢', '。', '當', '地', '人', '的', '惡', '夢', '。', '當', '地', '人', '的', '惡']\n",
      "epoch:\n",
      "800\n",
      "0m 44s\n",
      "loss:\n",
      "tensor(4.9393)\n",
      "['當', '局', '目', '前', '認', '定', '還', '沒', '有', '關', '閉', '閘', '門', '的', '必', '要', '。', '威', '尼', '斯', '絡', '繹', '不', '絕', '的', '觀', '光', '客', '，', '已', '經', '成', '為', '當', '地', '人', '的', '惡', '夢', '。', '當', '地', '人', '的', '惡', '夢', '。', '當', '地', '人', '的', '惡']\n",
      "epoch:\n",
      "900\n",
      "0m 49s\n",
      "loss:\n",
      "tensor(4.9207)\n",
      "['當', '局', '目', '前', '認', '定', '還', '沒', '有', '關', '閉', '閘', '門', '的', '必', '要', '。', '威', '尼', '斯', '絡', '繹', '不', '絕', '的', '觀', '光', '客', '，', '已', '經', '成', '為', '當', '地', '人', '的', '惡', '夢', '。', '當', '地', '人', '的', '惡', '夢', '。', '當', '地', '人', '的', '惡']\n",
      "training time :  0m 55s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for epoch in range(1000):\n",
    "    total_loss = torch.FloatTensor([0])\n",
    "    \n",
    "    #for trigramsItem in trigramsList:\n",
    "    for context, target in trigramsList:\n",
    "            # step 1:\n",
    "            # �Ncontext(ex : ['When','forty'])�ഫ��index(ex : [68, 15])\n",
    "            # �A�নpytorch��variable\n",
    "        context_idxs = [word_to_ix[w] for w in context]\n",
    "        context_var = autograd.Variable(torch.LongTensor(context_idxs))\n",
    "\n",
    "            # step 2:\n",
    "            # �M��gradient�A����W�@�����֭p\n",
    "        model.zero_grad()\n",
    "\n",
    "            # step 3:\n",
    "            # ��variable�ܼƶi�h�]forward\n",
    "        log_probs, embedd = model(context_var)\n",
    "\n",
    "            # step 4:\n",
    "            # �p��loss(��target variable��i�h)\n",
    "        loss = loss_function(log_probs, autograd.Variable(torch.LongTensor([word_to_ix[target]])))\n",
    "        \"\"\"\n",
    "        print(log_probs)\n",
    "        print(autograd.Variable(torch.cuda.LongTensor([word_to_ix[target]])))\n",
    "        print(loss)\n",
    "        print('-----------------------------------')\n",
    "        \"\"\"\n",
    "            # step 5:\n",
    "            # �]backward�A��sgradient\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.data\n",
    "    losses.append(total_loss)\n",
    "        #losses.append(total_loss)\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print('epoch:')\n",
    "        print(epoch)\n",
    "        print(time_since(start_time))\n",
    "        print('loss:')\n",
    "        print(total_loss[0])\n",
    "        sentence = ['當','局']\n",
    "        predict_word = ''\n",
    "        count = 0\n",
    "\n",
    "        while count < 50 :\n",
    "            word_in = autograd.Variable(torch.LongTensor([word_to_ix[i] for i in sentence[len(sentence)-2:len(sentence)]]))\n",
    "            out, outEmbedd = model(word_in)\n",
    "            _, predict_label = torch.max(out,1)\n",
    "            predict_word = ix_to_word[predict_label.data[0].item()]\n",
    "            #sentence.insert(0, predict_word)\n",
    "            sentence.append(predict_word)\n",
    "            count += 1\n",
    "        print(sentence)\n",
    "        sentence = []\n",
    "print(\"training time : \",time_since(start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1cfda588>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving done & predicting...\n",
      "['當', '局', '目', '前', '認', '定', '還', '沒', '有', '關', '閉', '閘', '門', '的', '必', '要', '。', '威', '尼', '斯', '絡', '繹', '不', '絕', '的', '觀', '光', '客', '，', '已', '經', '成', '為', '當', '地', '人', '的', '惡', '夢', '。', '當', '地', '人', '的', '惡', '夢', '。', '當', '地', '人', '的', '惡']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "print('saving model...')\n",
    "torch.save(model, '0_test.pkl')\n",
    "state = {\n",
    "    'epoch': 10,\n",
    "    'state_dict': model.state_dict(),\n",
    "    'optimizer' : optimizer.state_dict()\n",
    "}\n",
    "torch.save(state, '0_testArg.pt')\n",
    "\"\"\"\n",
    "\n",
    "### predict\n",
    "print('saving done & predicting...')\n",
    "\n",
    "sentence = ['當','局']\n",
    "predict_word = ''\n",
    "count = 0\n",
    "\n",
    "while count < 50 :\n",
    "    word_in = autograd.Variable(torch.LongTensor([word_to_ix[i] for i in sentence[len(sentence)-2:len(sentence)]]))\n",
    "    out, outEmbedd = model(word_in)\n",
    "    _, predict_label = torch.max(out,1)\n",
    "    predict_word = ix_to_word[predict_label.data[0].item()]\n",
    "    #sentence.insert(0, predict_word)\n",
    "    sentence.append(predict_word)\n",
    "    count += 1\n",
    "print(sentence)\n",
    "sentence = []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
